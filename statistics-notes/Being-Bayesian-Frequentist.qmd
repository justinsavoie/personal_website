---
title: "[Am I a Bayesian or a Frequentist?](index.html)"
format:
  html:
    embed-resources: true
    toc: true
    toc-location: left
editor: visual
---

For many applied social science problems (relatively simple versions of linear regression, descriptive statistics) it doesn't seem to matter much.

Frequentists use Maximum Likelihood Estimation (MLE) to obtain point estimates for parameters. Bayesians, on the other hand, combine the likelihood with a prior distribution using Bayes' theorem to obtain a posterior distribution. It's like taking a weighted average of the MLE estimate and the prior.

Bayesians often employ vague or not-very-informative priors. Consequently, the posterior distribution of their estimates tends to align closely with the MLE estimates.

There are packages that do very easily the Bayesian versions of stuff like `lm()`, `glm()`, `lmer()` and `glmer()` (mostly `rstanarm` and `brms`).

The results are often similar to what you would get with `lm()`, `glm()`. Importantly, if the results are not similar, you should try to understand why.

In practice, I'll often use frequentist methods because they are much faster on large datasets. Most people are trained with frequentist statistics so that's also what they know.

I'll sometimes use `rstanarm` and `brms` if I need the full posterior distribution of parameters because I want to get the downstream uncertainty; like poststratified predictions. We can also get these with bootstrap or the delta method. But there's something nice with getting the full posterior.

My high level view is something like section 5.5.5 of Kevin Murphy's [book](probml.github.io/pml-book/book1.html), especially the quote by Donald Rubin at the top of p. 203:

"The applied statistician should be Bayesian in principle and calibrated to the real world in practice. \[They\] should attempt to use specifications that lead to approximately calibrated procedures under reasonable deviations from \[their assumptions\]. \[They\] should avoid models that are contradicted by observed data in relevant ways --- frequency calculations for hypothetical replications can model a model's adequacy and help to suggest more appropriate models."

It's a [toy example](https://stats.oarc.ucla.edu/wp-content/uploads/2022/11/R_reg_2022.html#(25)) but for many applied problems it won't matter much either:

```{r,message=FALSE,warning=FALSE, results = 'hide'}
library(rstanarm)
d <- read.csv("https://stats.idre.ucla.edu/wp-content/uploads/2019/02/elemapi2v2.csv")
fit <- lm(api00 ~  enroll + meals + full, data = d)
fitBayes <- stan_glm(api00 ~  enroll + meals + full, data = d)
```

```{r}
coef(summary(fit))[,1:2]
fitBayes[1:2]
```
