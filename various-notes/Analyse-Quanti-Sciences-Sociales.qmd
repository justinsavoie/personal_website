---
title: "[L'analyse quantitative en sciences sociales](index.html)"
format:
  html:
    embed-resources: true
    toc: false
    toc-location: left
editor: visual
---

La capture d'écran suivante est tirée d'un livre important sur l'analyse des données pour les sciences sociales par [Llaudet et Imai](https://press.princeton.edu/books/hardcover/9780691199429/data-analysis-for-social-science).

![Llaudet and Imai: Data Analysis for Social Science](figures/llaudet-imai-what-is-data-analysis.png)

## Mesurer, prédire et expliquer

En sciences sociales, on analyse les données pour **mesurer** ("décrire" est souvent utilisé de manière interchangeable), **prédire** ou **expliquer**.

On peut **mesurer** la proportion d'électeurs qui soutiennent une politique sur le changement climatique. On peut mesurer le revenu des ménages et la santé mentale des Canadiens. On peut mesurer la satisfaction à l'égard de la démocratie. On peut prendre ces mesures au niveau canadien (ou dans n'importe quel autre pays), mais on peut également les ventiler par province, par ville, etc. On parle d'inférence descriptive. On vient décrire et on utilise l'inférence statistique pour généraliser de notre échantillon à la population d'intérêt.

On peut **prédire**, par exemple le vainqueur probable d'une élection. En économie, on peut prédire le taux de croissance de la population, le taux de croissance du PIB. La prédiction est beaucoup utilisée en administration des affaires, en finance, en génie. Par exemple, si le Réseau de transport de la Capitale veut déterminer le nombre d'autobus à mettre en circulation sur différents parcours, ses analystes vont probablement utiliser l'analyse prédictive. Par exemple, étant donné l'heure de la journée, le jour de la semaine, on souhaite prédire le nombre de passagers. On ne veut pas nécessairement comprendre en profondeure l'impact de chaque facteur. On veut simplement de bonnes prédictions.

On peut **expliquer**, par exemple, l'effet causal de la fréquentation d'une école privée sur les résultats des élèves aux examens du ministère sur leurs revenus futurs; ou l'effet causal de l'utilisation des médias sociaux sur la susceptibilité à la mésinformation.

La distinction entre mesurer, prédire et expliquer est parfois floue. Par exemple, si je mesure la proportion d'électeurs qui soutiennent une politique sur le changement climatique, peut-être que je souhaite voir si cette proprotion évolue dans le temps, si descriptivement, le support est différent dans différentes provinces. Dans ce cas, est-ce que je fais de l'explication ? Le temps/la géographie comme facteur explicatif? Est-ce que le lieu de résidence "cause" ces changements. Ce sont des questions complexes. Même chose pour l'exemple du Réseau de transport de la Capitale. Dans un sens, clairement, un bon modèle prédictif peut aussi expliquer. Mes variables que j'utilise pour prédire sont aussi des facteurs explicatifs. D'un point de vue académique et scientifique, l'apprentissage automatique et l'analyse prédictive ont récemment suscité un grand intérêt théorique quant à l'importance de la réflexion sur la causalité dans le cadre de la prédiction.

Néanmoins, cette distinction entre mesurer, prédire et expliquer demeure utile pour comprendre les différents buts de la science. Voici un point de vue similaire exprimé par un [biostatisticien appliqué, Demetri Pananos](https://dpananos.github.io/) sur Twitter.

![Ph.Demetri (Demetri Pananos Ph.D) sur Twitter".](figures/desc-caus-pred.png)

## Expliquer: la causalité

L'explication causale est centrale en science sociale. Un exemple classique d'explication causale en science politique est l'hypothèse selon laquelle le développement économique favorise la démocratisation. L'argument sous-jacent est que la croissance économique engendre une classe moyenne plus large et plus éduquée, qui réclame ensuite davantage de participation politique et de droits civiques, conduisant à des réformes démocratiques. Une autre explication causale courante en science politique est l'influence des institutions politiques sur la stabilité et la performance d'un pays. Par exemple, on peut arguer que les systèmes parlementaires favorisent une plus grande stabilité politique que les systèmes présidentiels, en raison de leur capacité à faciliter la formation de gouvernements de coalition et à éviter les impasses politiques.

Je suppose (mon expertise en dehors des sciences sociales est limitée) qu'il en va de même dans d'autres domaines. Par exemple, la manière dont une forêt est gérée (par exemple, la coupe sélective versus la coupe à blanc) a un impact direct (causal) sur la biodiversité au sein de cet écosystème. L'argument sous-jascent est que la coupe sélective, où seulement certains arbres sont prélevés, tend à préserver une plus grande diversité d'habitats par rapport à la coupe à blanc, qui peut détruire de vastes zones d'habitat et diminuer la biodiversité. D'ailleurs, le méchanisme causal est probablement plus évident dans cet exemple que dans les deux cas précédent de science politique.

Dans tous ces cas, la conceptualisation (la création de définitions spécifiques pour les concepts abstraits ou les variables que les chercheurs ont l'intention d'examiner) et l'opérationnalisation (le processus consistant à décider exactement comment un concept sera mesuré ou représenté dans la recherche empirique) sont essentielles.

------------------------------------------------------------------------

La norme de référence (*gold standard*) pour l'analyse causale en recherche est l'essai contrôlé randomisé (Randomized controlled trials - RCT en anglais), principalement en raison de sa capacité unique à établir une relation de cause à effet entre une intervention et ses résultats. Les RCT reposent sur la randomisation, qui consiste à attribuer aléatoirement les participants à un groupe de traitement (recevant l'intervention) ou à un groupe témoin (ne recevant pas l'intervention ou recevant un placebo). En assurant que les deux groupes soient comparables avant l'intervention, toute différence observée dans les résultats peut être attribuée avec plus de confiance à l'effet de l'intervention elle-même, plutôt qu'à d'autres facteurs externes. Cela rend les RCT particulièrement puissants pour tester l'efficacité de nouveaux traitements médicaux, interventions éducatives, ou politiques publiques.

Considérez l'hypothèse selon laquelle le progrès économique contribue à la démocratisation. Imaginez, à titre d'exemple, un scénario (100% fictif) dans lequel vous disposez de 2000 nations. Vous attribuez de manière aléatoire à la moitié d'entre elles un niveau élevé de développement économique, tandis que l'autre moitié reçoit un niveau faible. Vous procédez ensuite à une analyse statistique pour évaluer l'effet de ce développement sur leurs processus de démocratisation. Cette démarche avec un RCT représente le *gold standard* en matière d'analyse causale, car l'attribution *aléatoire* du "traitement" (soit un développement économique fort, soit faible) permet de s'assurer que toute différence observée dans la démocratisation est directement attribuable à ce facteur, toutes les autres variables étant contrôlées par la randomisation. Évidemment, cet exemple reste purement théorique et évidemment impossible dans la pratique, ce qui explique pourquoi les chercheurs se tournent vers des méthodes observationelles pour étudier de telles hypothèses. Mais c'est utile de réfléchir de cette façon.

En général, il y a deux problèmes avec les méthodes observationelles. Premièrement, on veut savoir si x cause y. Mais peut-être que c'est y qui cause x, et avec des méthodes observationelles par étude transversale (des données collectées une fois dans le temps; par exemple un sondage) on ne peut pas vraiment exclure cette possibilité que ça soit y qui cause x. On appelle ça la causalité inversée. (Peut-être que la démocratisation cause le progrès économique.)

Deuxièmement, il se peut qu'un autre facteur cause à la fois de x et de y. C'est ce que on appelle variable confondante (Peut-être que d'autres facteurs causent à la fois le progrès économique et la démocratisation: ressources naturelles, culture, niveau de revenu initial, structure institutionelle). Bref, ce ne sont que des exemples, mais vous voyez l'idée.

En général, il est admis que c'est possible possible d'étudier une relation causale avec des données observationelles. Le chapitre 3 de Kellstedt et Whitten nous dit que: "To speak more generally, if we wish to know whether some X → Y, we need to cross four causal hurdles: (1) Is there a credible causal mechanism that connects X to Y? (2) Can we eliminate the possibility that Y causes X? (3) Is there covariation between X and Y? (4) Is there some Z related to both X and Y that makes the observed relationship between X and Y spurious?"[^1]

[^1]: \(3\) est controversé. "Is there covariation between X and Y?" Techniquement, ce n'est pas nécessaire qu'une corrélation/covariation soit observée. Peut-être qu'une corrélation/covariation n'est pas observée, mais que c'est à cause de variables confondantes.

Parfois, les méthodes quasi-expérimentales comblent cet espace entre les méthodes expérimentales et observationelles. Voir par exemple, [l'article wikipedia](https://en.wikipedia.org/wiki/Quasi-experiment).

Plus techniquement, souvent les chercheurs réfléchissent à la causalité à travers le [modèle causal de Rubin](https://en.wikipedia.org/wiki/Rubin_causal_model). Le modèle causal de Rubin est basé sur l'idée de **résultats potentiels**. Par exemple, une personne aurait un *certain revenu* à l'âge de 40 ans si elle avait fréquenté l'université, tandis qu'elle aurait un *autre certain revenu, différent,* à l'âge de 40 ans si elle n'avait pas fréquenté l'université. Pour mesurer l'effet causal de l'entrée à l'université pour cette personne, nous devons comparer le résultat pour le même individu dans les deux futurs alternatifs. Comme il est évidemment impossible d'observer les deux résultats potentiels à la fois, l'un des résultats potentiels est toujours manquant. Ce dilemme est le "problème fondamental de l'inférence causale". Ici, les essais contrôlés randomisés sont une bonne solution: si le traitement est distribué de manière totalement aléatoire sur un échantillon suffisamment large, la comparaison des résultats des personnes traitées (allé à l'université) et des personnes non traitées (pas allé à l'université) permet d'évaluer approximativement l'effet causal du traitement.

Et ce modèle causal de Rubin, intuitivement, fait beaucoup de sens. Pensez-y: quel est l'effet si madame X prend le vaccin VS ne prend pas le vaccin? Quel est l'effet si monsieur X va à l'université VS ne va pas à l'université. Quel est l'effet si on donne un fertilisant à une parcelle de terre VS si on ne donne pas le fertilisant? Quel est l'effet de la confiance d'une personne envers le gouvernement sur l'adoption/respect des règles/l'utilisation d'une politique, un service? Et ainsi de suite.

Cette idée générale est beaucoup utilisée dans l'analyse économique de l'effet des politiques gouvernementales. Si un certain programme est implémenté, quel est le résultat; si le programme n'est pas implémenté, quel est le résultat? C'est pourquoi vous entendrez souvent dire que les essais contrôlés randomisés constituent le "gold standard".
