---
title: "[EFA vs PCA](index.html)"
format:
  html:
    embed-resources: true
    toc: false
    toc-location: left
editor: visual
---

En science sociale, les chercheurs hésitent parfois entre l'analyse factorielle exploratoire (EFA en anglais) et l'analyse en composantes principales (PCA en anglais). Cette hésitation provient du fait que ces deux méthodes servent à réduire la dimensionnalité des données mais s'appuient sur des principes et des objectifs légèrement différents. L'EFA vise à identifier les structures sous-jacentes (facteurs) qui expliquent les corrélations entre les variables observées, tandis que la PCA vise à réduire la dimensionnalité des données en transformant les variables observées en un nouveau jeu de variables non corrélées, appelées composantes principales, qui capturent le maximum de variance des données.

En général, si la recherche vise à tester une théorie ou à valider un concept, l'AFE peut sera plus appropriée car elle cherche à identifier les facteurs sous-jacents qui expliquent les variables (ou indicateur) observées.

Si la recherche est plus exploratoire, ou plus prédictive, ou vise à simplifier les données sans qu'il soit nécessaire d'identifier les concepts sous-jacents, PCA peut être plus appropriée car elle se concentre sur la variance et la réduction pure des données.

Le chapitre 13 de [Using Multivariate Statistics](https://www.pearson.com/en-us/subject-catalog/p/using-multivariate-statistics/P200000003097/9780137526543) est excellent pour discuter ces différences. Ce chapitre est disponible [ici](figures/Barbara G. Tabachnick, Linda S. Fidell - Using Multivariate Statistics-Pearson (2012) C13.pdf).

## Un exemple

Le jeu de données "mtcars" dans R est un ensemble de données "exemple" souvent utilisé pour l'illustration des concepts d'analyse de données et de statistique. Il contient les données de 32 automobiles (1973–74) sur 11 aspects différents tels que la consommation de carburant (mpg), le nombre de cylindres (cyl), la puissance (hp), le poids (wt), et la vitesse maximale (qsec), entre autres. Ces données permettent de pratiquer la manipulation de données, l'analyse exploratoire, ainsi que des techniques de modélisation statistique. Pour plus d'infos: `?mtcars`.

On va supprimer les variables dummy et on va traiter les 9 autres variables comme des variables continues.

```{r}
head(mtcars)
mtcars2 <- mtcars[,c("mpg", "cyl", "disp", "hp", "drat", "wt",
                     "qsec","gear", "carb")]
head(mtcars2)
```

Pour une analyse factorielle exploratoire, on doit spécifier le nombre de facteurs. 

On peut faire une analyse factorielle à un facteur. Ici, donc, on spécifie un modèle où il y a une variable latente (disons "puissance de la voiture") et cette variable explique/est à la cause de des autres variables qu'on mesure. 

Lorsque les indicateurs de fiabilité indiquent une concomitance significative entre un groupe de variables, on peut émettre l’hypothèse que ces variables mesurent une même variable latente (ici la puissance de la voiture).

```{r}
factanal(mtcars2,1)
```

Pour l'analyse factorielle, il n'est pas nécessaire que les variables soient toutes dans la même direction. Simplement, les coefficients de saturation (factor loadings) seront négatifs. Par contre, pour calculer le Cronbach's alpha, elles doivent être dans la même direction. On va inverser les variables qui sont négativement corrélées. 


```{r}
mtcars2$mpg <- mtcars2$mpg*-1
mtcars2$drat <- mtcars2$drat*-1
mtcars2$qsec <- mtcars2$qsec*-1
mtcars2$gear <- mtcars2$gear*-1
```

Les résultats de l'analyse factorielle sont les mêmes, mais maintenant les coefficients de saturation sont tous positifs.

```{r}
factanal(mtcars2,1)
```

On va regarder le alpha standardized. 0.92 c'est excellent.

```{r}
psych::alpha(mtcars2)
```

La première valeur propre:

```{r}
eigen(cor(mtcars2))
```