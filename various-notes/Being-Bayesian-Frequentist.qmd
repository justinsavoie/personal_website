---
title: "[Am I a Bayesian or a Frequentist?](index.html)"
format:
  html:
    embed-resources: true
    toc: true
    toc-location: left
editor: visual
---

For many applied social science problems (for example relatively simple versions of linear regression, descriptive statistics where you still use a model, etc.) [it doesn't seem to matter much](https://online.ucpress.edu/collabra/article/4/1/31/112994/Credible-Confidence-A-Pragmatic-View-on-the).

Frequentists use Maximum Likelihood Estimation (MLE) to obtain point estimates for parameters. Bayesians, on the other hand, combine the likelihood with a prior distribution using Bayes' theorem to obtain a posterior distribution. It's like taking a weighted average of the MLE estimate and the prior.

In social science, Bayesians often employ vague or not-very-informative priors. Consequently, the posterior distribution of their estimates tends to align closely with MLE estimates.

There are packages that do very easily the Bayesian versions of things like `lm()`, `glm()`, `lmer()` and `glmer()` (mostly `rstanarm` and `brms`).

The results are often similar to what you would get with `lm()`, `glm()`... Importantly, if the results are not similar, you should try to understand why.

In practice, I'll often use frequentist methods because they are much faster on large datasets. Most people are trained with frequentist statistics so that's also what they know.

I'll sometimes use `rstanarm` and `brms` if I need the full posterior distribution of parameters because I want to get the downstream uncertainty; like poststratified predictions. We can also get these with bootstrap or the delta method. But there's something nice with getting the full posterior.

My high level view is something like section 5.5.5 of Kevin Murphy's [book](probml.github.io/pml-book/book1.html), especially the quote by Donald Rubin at the top of p. 203:

"The applied statistician should be Bayesian in principle and calibrated to the real world in practice. \[They\] should attempt to use specifications that lead to approximately calibrated procedures under reasonable deviations from \[their assumptions\]. \[They\] should avoid models that are contradicted by observed data in relevant ways --- frequency calculations for hypothetical replications can model a model's adequacy and help to suggest more appropriate models."

Both for Frequentists and Bayesians, the parameter to estimate ["may have been fixed from the start or may have been generated from a physically random mechanism"](https://academic.oup.com/ije/article/35/3/765/735529). The difference is that Bayesians will estimate a probability model for parameters given the model and their priors on these parameters, while Frequentists will estimate the most likely point estimate given the model and will use the standard error of the parameter to provides a measure of the uncertainty or variability associated with the estimate (e.g., if we replicated that experiment 100 times, the parameter true would be contained in the confidence interval 95 times). Seems to me to be a pragmatic choice. 

Here is a [toy example](https://stats.oarc.ucla.edu/wp-content/uploads/2022/11/R_reg_2022.html#(25)) but for many applied problems it won't matter much either:

```{r,message=FALSE,warning=FALSE, results = 'hide'}
library(rstanarm)
d <- read.csv("https://stats.idre.ucla.edu/wp-content/uploads/2019/02/elemapi2v2.csv")
fit <- lm(api00 ~  enroll + meals + full, data = d)
fitBayes <- stan_glm(api00 ~  enroll + meals + full, data = d, seed = 222)
```

```{r}
coef(summary(fit))[,1:2]
fitBayes[1:2]
```

For example if we look at the coefficient on the intercept, it's 801.83 for MLE and 801.96 for the Bayesian fit. The prior chosen automatically by `rstanarm` for that coefficient is $N(648,356)$. That's what is meant by some kind of weighted average of the prior and the likelihood. As is the case with all applied regression models like this one, the likelihood strongly dominates the prior. 

```{r}
prior_summary(fitBayes)
```

Of course you can also set an implausibly very precise prior. It's not clear why you would do that...

```{r,message=FALSE,warning=FALSE, results = 'hide'}
fitBayes <- stan_glm(
  api00 ~ enroll + meals + full, 
  data = d, 
  prior_intercept = normal(0, 1), 
)
```
```{r}
fitBayes[1:2]
```